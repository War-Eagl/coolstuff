{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15-11-2021-Sketchinator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMkdr0ifQt95"
      },
      "source": [
        "# \"Anybody can be a Picasso\"\n",
        " > \"When AI gives you a little helping hand\"\n",
        "\n",
        "- toc:true\n",
        "- branch: master\n",
        "- badges: true\n",
        "- comments: true\n",
        "- author: Vishal\n",
        "- categories: [Deep Learning, Human Computer Interaction, Research, Computational creativity, Co-Creative AI]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LubUF6XETyiC"
      },
      "source": [
        "# Art and AI\n",
        "\n",
        "![](https://media.istockphoto.com/photos/cyborg-drawing-picture-picture-id937060922?k=20&m=937060922&s=612x612&w=0&h=UaruxFMZhRJ194EnJXI5t9CZXIYMGZnwkW5KTyK4yoc=)\n",
        "\n",
        "\n",
        "Art is the thing that is driving forward the human evolution. It was an artist's mind which seeked symmetry, that created \"Circular shaped stone\", that became wheel and drove the humanity forward. \n",
        "\n",
        "It was pieces of art that triggered lot of great moments in history like **French Revolution**, **October Revolution**, etc. In short we owe to art a lot. \n",
        "\n",
        "However, not every person in earth has liberty to express themselves through creating art. This is due to several factors as art requires certain expertise, time commitment towards it, which is a luxury that cannot be afforded by lot of people. One can't just take up a canvas and draw their masterpiece. \n",
        "\n",
        "Here's where AI comes in. Humans are known to use **tools** to bridge the skill gaps. This time around, AI comes as our handy tool. Computational creativity aims this, \"Got a cool idea for a poem or art? Great, tell me that and we'll convert into something presentable, **together**\". It doesn't take jobs away from artists, but rather, create more artists. Quoting from Prof. Mark Riedl in his [Ted talk](https://www.youtube.com/watch?v=h8aS78RZx5E), \"*What will you create? if you know that you can't fail*\"\n",
        "\n",
        "In the similar lines, let me talk about my research at **Design with AI Lab**, University of Sydney along with my mentor **Dr. Kazjon Grace** and my friend **Narasimhan**. We are working on **Sketchinator**, co-creative AI that assists in sketching. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEGyooMfPbCB"
      },
      "source": [
        "# Behold!!! The Sketchinator\n",
        "\n",
        "<a href=\"https://ibb.co/7C882BZ\"><img src=\"https://i.ibb.co/KhRRFBf/Whats-App-Image-2021-11-14-at-5-03-17-PM.jpg\" alt=\"Whats-App-Image-2021-11-14-at-5-03-17-PM\" border=\"0\"></a>\n",
        "\n",
        "\n",
        "\n",
        "Sketchinator (obviously inspired from Dr. Doofenshmirtz infamous inators), has three components:\n",
        "\n",
        "\n",
        "\n",
        "> 1.   A web based platform where users can draw their sketches\n",
        "> 2.   A sequential model to predict immediate strokes\n",
        "> 3.   An Encoder-Decoder model to look the image as whole.  \n",
        "\n",
        "\n",
        "Let's look at each of these components in detail.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM9w-E_ZALCg"
      },
      "source": [
        "# Web App - The face\n",
        "\n",
        "Web app is the interface where user draws their sketches.\n",
        "\n",
        "Think this analogous to **VSCode app with copilot plugin turned on**, but for a app that looks like **MS Paint**. While the user can start drawing the sketches, the app does the following:\n",
        "\n",
        "(PS. I'm an awful artist)\n",
        "## Sketch autocomplete\n",
        "\n",
        "<a href=\"https://ibb.co/yQyQGX8\"><img src=\"https://i.ibb.co/Js7s0Kz/cat.png\" alt=\"cat\" border=\"0\"></a>\n",
        "\n",
        "The user starts their sketch and does few strokes, revealing the outline of the object he's trying to draw. (*Black Strokes*)\n",
        "\n",
        "Then the transformer model reads those strokes as sequence of points and predicts the next few strokes. (*Red Strokes*)\n",
        "\n",
        "Also the encoder-decoder model takes the rasterized version of the sketch and predicts how the complete image looks like (*Yellow Strokes*)\n",
        "\n",
        "This can also work like:\n",
        "\n",
        "## Filling Background and details\n",
        "\n",
        "<a href=\"https://ibb.co/1RrdS3g\"><img src=\"https://i.ibb.co/gtSPnG2/house.png\" alt=\"house\" border=\"0\"></a>\n",
        "\n",
        "The user draws the basic outline of the object he intends to draw (*Black Strokes*)\n",
        "\n",
        "The transformer model will draw the details inside the fill in the details of the object (*Red Strokes*)\n",
        "\n",
        "The encoder-decoder model will paint the background details of the sketch (*Yellow Strokes*)\n",
        "\n",
        "Also it an do this:\n",
        "\n",
        "## Prompt based sketch retrieval\n",
        "\n",
        "<a href=\"https://ibb.co/PWK0jNk\"><img src=\"https://i.ibb.co/s1nzR27/car.png\" alt=\"car\" border=\"0\"></a>\n",
        "\n",
        "There is also an option to describe the sketch in words and both models will try to sketch the description."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzQm0aG_uZMD"
      },
      "source": [
        "# Transformer Model\n",
        "\n",
        "The [sketch-rnn](https://arxiv.org/abs/1704.03477) (from **Magenta** team of Google Brain) tells the way to treat sketches as sequences, rather than images, and train neural sequence models on them. \n",
        "\n",
        "They convert sketches to a format called as *Stroke-5* format which convert each point into five dimensional vector consisting of,\n",
        "\n",
        ">> Δx -> offset in x axis (change in x direction from previous point)\n",
        "\n",
        ">> Δy -> offset in y axis (change in y direction from previous point)\n",
        "\n",
        ">> p1 -> boolean variable, '1' if the point is in middle of a stroke, '0' otherwise\n",
        "\n",
        ">> p2 -> boolean variable, '1' if point is at end of a stroke, '0' otherwise\n",
        "\n",
        ">> p3 -> boolean variable, '1' if point is at end of entire sketch, '0' otherwise\n",
        "\n",
        "\n",
        "The [Quick, Draw!](https://github.com/googlecreativelab/quickdraw-dataset) dataset converted to above format and used to train the sketch-rnn\n",
        "\n",
        "This idea is further expanded to training a transformer model instead of RNN, as transformers outperfom RNNs in every aspect, so far. That's how [Sketch-BERT](https://arxiv.org/abs/2005.09159) is born. \n",
        "\n",
        "RNNs had some limitiation, that they are bad if the strokes become very long or for sketches with lot of strokes. \n",
        "\n",
        "Transformers overcome this limitation by tracking the long term elements through their attention mechanism. \n",
        "\n",
        "Therefore the transformer models are better at drawing the intricate details of the sketch. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bz2rRTE7GdJ"
      },
      "source": [
        "# Encoder-Decoder Model\n",
        "\n",
        "A sketch is more than a set of strokes. An skillfull artist will not only concentrate on the individual strokes but he'll also keep an eye on how the entire painting is coming together.\n",
        "\n",
        "Likewise, eventhough the transformer model has an eye for detail, it fails to see the bigger picture. Therefore we need a model to see the image as whole. We propose a following block diagram, \n",
        "\n",
        "<a href=\"https://ibb.co/fCfRc4F\"><img src=\"https://i.ibb.co/VvRyK29/VQGAN-Sketchinator.png\" alt=\"VQGAN-Sketchinator\" border=\"0\"></a>\n",
        "\n",
        "\n",
        "*   Partially drawn sketch is rasterized and passed through VQGAN\n",
        "*   [VQGAN](https://compvis.github.io/taming-transformers/) converts it into realistic render of the image\n",
        "*   The realistic images are passed through [PhotoSketch](https://github.com/mtli/PhotoSketch) which converts them into full contour drawing.\n",
        "*   Since the VQGAN interprets the sketch and convert into full image of the object, ie., that if you had drawn a cat partially, VQGAN interprets that it's a cat and gives out full cat image as output. \n",
        "*   The partial and full images go through a Y shaped network (two inputs, connected through a stem and gives out one output), called \"Y-Net\" which tells how dissimilar is the full sketch is to the partial sketch\n",
        "*   Based on the loss of Y-Net, the latent space of VQGAN by means of Genetic algorithms or Gradient Descent (Gradients won't pass through Y-Net or Photosketch) to minimise Y-Net loss. \n",
        "\n",
        "\n",
        "In way VQGAN can figure out the broad details of the sketch and present it to the user.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBIa5aosByD8"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "This is based on the research proposal I submitted to Design with AI lab. These exact specifications might change on the actual sketchinator as we are still early on the research. Nevertheless, our goal is to create a tool that can assist and simplify the process of translating ideas into quick sketches. By no means, the aim of the tool is to create your next masterpiece, but a quick sketch to show to your family, friends or your boss. Thank you so much for reading this far. Reach out for any queries, ideas, or basically anything."
      ]
    }
  ]
}